{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIGIT RECOGNIZATION",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "P5uCIVt5FJ_0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mg4xCPz0FVPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zi2Yej5sFctB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y1aCTSEWFfGK",
        "colab_type": "code",
        "outputId": "dfa0ed2a-7dd8-4c3c-f96f-26cd016b42eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading train.csv to /content\n",
            " 85% 62.0M/73.2M [00:01<00:00, 20.7MB/s]\n",
            "100% 73.2M/73.2M [00:01<00:00, 40.0MB/s]\n",
            "Downloading test.csv to /content\n",
            " 84% 41.0M/48.8M [00:00<00:00, 38.6MB/s]\n",
            "100% 48.8M/48.8M [00:00<00:00, 71.2MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 79.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R362zaYLFl4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3569xI6FpxJ",
        "colab_type": "code",
        "outputId": "769ef57b-66b1-483e-f40d-983381b0bf2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/train.csv\")\n",
        "print(data.shape)\n",
        "y=[]\n",
        "X=[]\n",
        "print(type(data))\n",
        "print(data.shape)\n",
        "data=data.values\n",
        "for i in range(42000):\n",
        "  image_array=[]\n",
        "  y.append(data[i][0])\n",
        "  for j in range(1,785):\n",
        "    image_array.append(data[i][j])\n",
        "  X.append(image_array)\n",
        "print(len(X))\n",
        "print(len(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 785)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(42000, 785)\n",
            "42000\n",
            "42000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VW1UONM9FroJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X=np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b41orQ0WMqLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X=X/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Huf_HAJZNYOu",
        "colab_type": "code",
        "outputId": "bf8be7e7-f81a-4565-fd9f-cb462b260550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train=[]\n",
        "for i in X:\n",
        "  i=i.reshape(28,28)\n",
        "  x_train.append(i)\n",
        "print(len(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mpHu3xkjNje-",
        "colab_type": "code",
        "outputId": "6ee3ed99-02d5-405f-cf1a-a7d94729b9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_train[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NFYm83ZGOAa9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sV0Fb2z-ORSu",
        "colab_type": "code",
        "outputId": "7162476c-13df-490b-fb0c-2cb5700dead5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "py.imshow(x_train[3])\n",
        "print(y[3])\n",
        "y=np.array(y)\n",
        "y.reshape(1,42000)\n",
        "print(y.shape)\n",
        "x_train=np.array(x_train).reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "(42000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAcCAWAKAwf8BrK7I/hUtNaYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wmNXXQT-OVq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D,MaxPooling2D\n",
        "from tensorflow.python.keras.layers.core import Dense,Activation,Flatten\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "#x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
        "#model=tf.keras.models.Sequential() #feed free model and the most common one\n",
        "#model.add(tf.keras.layers.Flatten())   #input layer and also a layer is flatten as we get a one directional array same as numpy.reshape will do\n",
        "\n",
        "\n",
        "x_train=np.array(x_train).reshape(-1,28,28,1)\n",
        "layers=[32,64,128,256]\n",
        "dense=[2,3,4,5,6,7,8]\n",
        "conv_layer=[]\n",
        "for layer_size in layers:\n",
        "  for l in dense:\n",
        "    for conv in conv_layer:\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(layer_size,(3,3),input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation(\"relu\"))\n",
        "      model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "      for l in range(conv-1):\n",
        "        model.add(Conv2D(layer_size,(3,3)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      for i in range(l):\n",
        "        model.add(tf.keras.layers.Dense(layer_size,activation=tf.nn.relu))   #dense layer Dense(no. of neuron ,activation function)\n",
        "\n",
        "      model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))   #output layer(no. of classification ,activation function will be softmax as it is probability distribution)\n",
        "      model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])   #we will try to set some parameters optimizer for optimization, how to calculate loss as nn always try to minimize the loss and meter of the nn\n",
        "      model.fit(x_train,y,epochs=3,validation_split=0.1)\n",
        "      print(str(layer_size)+'   '+str(l)+\"dense\"+\" \"+str(conv)+\" convlayer\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zdnnly3qPSjG",
        "colab_type": "code",
        "outputId": "a60d34b0-26fb-4a64-c484-106750374d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D,MaxPooling2D\n",
        "from tensorflow.python.keras.layers.core import Dense,Activation,Flatten\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "model=tf.keras.models.Sequential() #feed free model and the most common one\n",
        "model.add(Conv2D(64,(3,3),input_shape=x_train.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128,(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(256,(2,2)))      \n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64,activation=tf.nn.relu)) \n",
        "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))   #output layer(no. of classification ,activation function will be softmax as it is probability distribution)\n",
        "model.compile(optimizer='adam',\n",
        "           loss='sparse_categorical_crossentropy',\n",
        "           metrics=['accuracy'])   #we will try to set some parameters optimizer for optimization, how to calculate loss as nn always try to minimize the loss and meter of the nn\n",
        "model.fit(x_train,y,epochs=30,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 37800 samples, validate on 4200 samples\n",
            "Epoch 1/30\n",
            "37800/37800 [==============================] - 15s 405us/sample - loss: 0.1704 - acc: 0.9464 - val_loss: 0.0619 - val_acc: 0.9807\n",
            "Epoch 2/30\n",
            "37800/37800 [==============================] - 15s 398us/sample - loss: 0.0502 - acc: 0.9852 - val_loss: 0.0479 - val_acc: 0.9860\n",
            "Epoch 3/30\n",
            "37800/37800 [==============================] - 15s 389us/sample - loss: 0.0350 - acc: 0.9893 - val_loss: 0.0485 - val_acc: 0.9848\n",
            "Epoch 4/30\n",
            "37800/37800 [==============================] - 15s 399us/sample - loss: 0.0286 - acc: 0.9909 - val_loss: 0.0364 - val_acc: 0.9869\n",
            "Epoch 5/30\n",
            "37800/37800 [==============================] - 15s 401us/sample - loss: 0.0202 - acc: 0.9936 - val_loss: 0.0384 - val_acc: 0.9888\n",
            "Epoch 6/30\n",
            "37800/37800 [==============================] - 15s 398us/sample - loss: 0.0185 - acc: 0.9937 - val_loss: 0.0339 - val_acc: 0.9914\n",
            "Epoch 7/30\n",
            "37800/37800 [==============================] - 15s 402us/sample - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0378 - val_acc: 0.9914\n",
            "Epoch 8/30\n",
            "37800/37800 [==============================] - 15s 400us/sample - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0363 - val_acc: 0.9910\n",
            "Epoch 9/30\n",
            "37800/37800 [==============================] - 15s 402us/sample - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0365 - val_acc: 0.9900\n",
            "Epoch 10/30\n",
            "37800/37800 [==============================] - 15s 396us/sample - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0358 - val_acc: 0.9900\n",
            "Epoch 11/30\n",
            "37800/37800 [==============================] - 15s 394us/sample - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0524 - val_acc: 0.9883\n",
            "Epoch 12/30\n",
            "37800/37800 [==============================] - 15s 389us/sample - loss: 0.0088 - acc: 0.9976 - val_loss: 0.0421 - val_acc: 0.9881\n",
            "Epoch 13/30\n",
            "37800/37800 [==============================] - 15s 392us/sample - loss: 0.0080 - acc: 0.9978 - val_loss: 0.0462 - val_acc: 0.9893\n",
            "Epoch 14/30\n",
            "37800/37800 [==============================] - 15s 391us/sample - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0305 - val_acc: 0.9924\n",
            "Epoch 15/30\n",
            "37800/37800 [==============================] - 15s 393us/sample - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0646 - val_acc: 0.9855\n",
            "Epoch 16/30\n",
            "37800/37800 [==============================] - 15s 392us/sample - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0450 - val_acc: 0.9900\n",
            "Epoch 17/30\n",
            "37800/37800 [==============================] - 15s 395us/sample - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0693 - val_acc: 0.9874\n",
            "Epoch 18/30\n",
            "37800/37800 [==============================] - 15s 393us/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0420 - val_acc: 0.9912\n",
            "Epoch 19/30\n",
            "37800/37800 [==============================] - 15s 391us/sample - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0538 - val_acc: 0.9910\n",
            "Epoch 20/30\n",
            "37800/37800 [==============================] - 15s 394us/sample - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0447 - val_acc: 0.9902\n",
            "Epoch 21/30\n",
            "37800/37800 [==============================] - 15s 393us/sample - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0452 - val_acc: 0.9919\n",
            "Epoch 22/30\n",
            "37800/37800 [==============================] - 15s 392us/sample - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0546 - val_acc: 0.9893\n",
            "Epoch 23/30\n",
            "37800/37800 [==============================] - 15s 392us/sample - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0406 - val_acc: 0.9926\n",
            "Epoch 24/30\n",
            "37800/37800 [==============================] - 15s 385us/sample - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0681 - val_acc: 0.9864\n",
            "Epoch 25/30\n",
            "37800/37800 [==============================] - 15s 394us/sample - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0558 - val_acc: 0.9886\n",
            "Epoch 26/30\n",
            "37800/37800 [==============================] - 15s 393us/sample - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0898 - val_acc: 0.9850\n",
            "Epoch 27/30\n",
            "37800/37800 [==============================] - 15s 392us/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0459 - val_acc: 0.9914\n",
            "Epoch 28/30\n",
            "37800/37800 [==============================] - 15s 393us/sample - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0527 - val_acc: 0.9893\n",
            "Epoch 29/30\n",
            "37800/37800 [==============================] - 15s 391us/sample - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0637 - val_acc: 0.9876\n",
            "Epoch 30/30\n",
            "37800/37800 [==============================] - 15s 392us/sample - loss: 0.0057 - acc: 0.9987 - val_loss: 0.1016 - val_acc: 0.9805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6e18e0d7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}